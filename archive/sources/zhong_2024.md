# AI-generated Essays: Characteristics and Implications on Automated Scoring and Academic Integrity

**Source:** [arXiv:2410.17439](https://arxiv.org/abs/2410.17439)
**Authors:** Yang Zhong, Jiangang Hao, Michael Fauss, Chen Li, Yuan Wang
**Date:** October 2024

**Accessed:** 2026-01-31

## Abstract

Using large-scale empirical data, we examine and benchmark the characteristics and quality of essays generated by popular LLMs... Our findings highlight limitations in existing automated scoring systems, such as e-rater, when applied to essays generated or heavily influenced by AI.

## Key Findings (Mapped to Matrix)

- **e-rater Features:** Grammar, Mechanics, Usage, Style, Organization, Development, Word Complexity.
- **Cross-Model Detection:** Detectors trained on one model can often identify texts from others (generalization).
- **Perplexity:** 99.7% accuracy on GPT-4.
- **Essay Length/Structure:** AI tends to produce uniform structures.

## Methodology

- 2,000 essays (10 LLMs x 100).
- Comparison with human controls.
- Scoring via e-raterÂ® engine.
